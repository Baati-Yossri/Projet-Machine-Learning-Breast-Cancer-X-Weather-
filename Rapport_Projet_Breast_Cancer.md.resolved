# Rapport de Projet : Détection du Cancer du Sein (Breast Cancer)

## 1. Introduction et Objectifs

Ce projet a pour objectif de développer un modèle de machine learning capable de diagnostiquer le cancer du sein (tumeur maligne ou bénigne) à partir de caractéristiques histologiques issues d'images numérisées. Il s'agit d'un problème de **classification binaire**.

Le jeu de données utilisé est le **Breast Cancer Wisconsin (Diagnostic) Data Set**.

## 2. Analyse Exploratoire des Données (EDA)

### 2.1. Vue d'ensemble
*   **Dimensions :** Le dataset contient **569 échantillons** et **31 colonnes** (30 caractéristiques + 1 variable cible `target`).
*   **Variable Cible :**
    *   `0` : Malignant (Maligne) - *Cas positif (à détecter)*
    *   `1` : Benign (Bénigne)
*   **Types de données :** Toutes les caractéristiques sont numériques (`float64`).

### 2.2. Qualité des Données
*   **Valeurs manquantes :** Aucune valeur manquante n'a été détectée dans le jeu de données. La base est propre.
*   **Statistiques Descriptives :** Les caractéristiques (rayon moyen, texture, périmètre, aire, etc.) présentent des échelles très différentes (ex: `mean area` varie de 143 à 2501, tandis que `mean smoothness` varie de 0.05 à 0.16), ce qui justifie une étape de normalisation.

### 2.3. Visualisation
Plusieurs graphiques ont été générés pour comprendre la distribution des données :
*   **Countplot :** Visualisation de l'équilibre des classes (légère prédominance des cas bénins).
*   **Heatmap (Corrélation) :** Identification de fortes corrélations entre certaines variables (ex: rayon, périmètre et aire sont très corrélés), ce qui suggère une possible redondance d'information (multicolinéarité).
*   **Pairplot & Histogrammes :** Analyse des distributions individuelles et des relations entre paires de variables pour distinguer les classes.

## 3. Prétraitement (Preprocessing)

Avant l'entraînement des modèles, les étapes suivantes ont été appliquées :

1.  **Séparation des données (Train/Test Split) :**
    *   Le jeu de données a été divisé en un ensemble d'entraînement et un ensemble de test pour évaluer la capacité de généralisation des modèles.
2.  **Normalisation (StandardScaler) :**
    *   Utilisation de `StandardScaler` pour centrer et réduire les variables ($mean=0$, $std=1$).
    *   Cela est crucial pour des algorithmes basés sur la distance comme KNN ou SVM, afin d'éviter que les variables à grandes valeurs ne dominent le modèle.

## 4. Modélisation

Huit algorithmes de classification différents ont été entraînés et comparés :

1.  **Régression Logistique** : Modèle linéaire de base pour la classification.
2.  **K-Nearest Neighbors (KNN)** : Classifieur basé sur la proximité des voisins.
3.  **Support Vector Machine (SVM)** : Recherche d'un hyperplan optimal séparant les classes.
4.  **Naive Bayes** : Modèle probabiliste basé sur le théorème de Bayes.
5.  **Arbre de Décision (Decision Tree)** : Modèle non linéaire basé sur des règles de décision.
6.  **Forêt Aléatoire (Random Forest)** : Ensemble d'arbres de décision (Bagging) pour réduire la variance.
7.  **Gradient Boosting** : Ensemble d'arbres construits séquentiellement pour corriger les erreurs (Boosting).
8.  **XGBoost** : Version optimisée et performante du Gradient Boosting.

## 5. Évaluation et Résultats

Les modèles ont été évalués principalement sur leur **Précision (Accuracy)**, ainsi que sur la **Matrice de Confusion** et le **Rapport de Classification** (Précision, Rappel, F1-Score).

### Synthèse des Performances (Accuracy)

| Modèle | Précision (Accuracy) |
| :--- | :--- |
| **Logic Regression** | 97.66% |
| **Random Forest** | 97.66% |
| **SVM** | 96.49% |
| **Naive Bayes** | 96.49% |
| **Gradient Boosting** | 96.49% |
| **K Neighbors** | 95.90% |
| **XGBoost** | 95.32% |
| **Decision Tree** | 92.40% |

### Analyse des Résultats
*   La **Régression Logistique** et le **Random Forest** ont obtenu les meilleurs résultats avec une précision de **97.66%**.
*   Le **SVM** et le **Gradient Boosting** suivent de très près (96.49%).
*   Les modèles d'ensemble (Random Forest, Boosting) et les modèles linéaires robustes (LogReg, SVM) surperforment l'arbre de décision unique, qui a tendance à surapprendre (overfitting).

## 6. Conclusion

Ce projet a démontré qu'il est possible de prédire avec une très haute fiabilité (près de 98%) la nature d'une tumeur du sein à partir de ses caractéristiques.

**Recommandation :**
Le modèle **Random Forest** est recommandé pour sa robustesse et sa capacité à gérer des relations non linéaires, bien que la **Régression Logistique** offre une alternative simple et interprétable avec une performance équivalente sur ce jeu de données spécifique. Pour une application médicale, une attention particulière devrait être portée au **Rappel (Recall)** pour la classe "Maligne" afin de minimiser les faux négatifs (ne pas manquer un cancer).
